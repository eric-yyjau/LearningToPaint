{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hzwer/LearningToPaint/blob/master/LearningToPaint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFN3oT1Hkjfs"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/hzwer/LearningToPaint.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dp7N29tGkwQs"
   },
   "outputs": [],
   "source": [
    "cd LearningToPaint/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTbhmFyawzhO"
   },
   "source": [
    "Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0wTTzOEbvps"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-23 11:19:08--  https://drive.google.com/uc?export=download&id=1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4\n",
      "Resolving drive.google.com (drive.google.com)... 216.58.193.78, 2607:f8b0:4005:80b::200e\n",
      "Connecting to drive.google.com (drive.google.com)|216.58.193.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0o-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/b1b7hldcgi5gmg1o6g6u9pd4neoahuuq/1563904800000/10102393604162075786/*/1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2019-07-23 11:19:11--  https://doc-0o-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/b1b7hldcgi5gmg1o6g6u9pd4neoahuuq/1563904800000/10102393604162075786/*/1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4?e=download\n",
      "Resolving doc-0o-58-docs.googleusercontent.com (doc-0o-58-docs.googleusercontent.com)... 172.217.14.225, 2607:f8b0:400a:804::2001\n",
      "Connecting to doc-0o-58-docs.googleusercontent.com (doc-0o-58-docs.googleusercontent.com)|172.217.14.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘renderer.pkl’\n",
      "\n",
      "renderer.pkl            [   <=>              ]  42.12M  81.4MB/s    in 0.5s    \n",
      "\n",
      "2019-07-23 11:19:12 (81.4 MB/s) - ‘renderer.pkl’ saved [44165821]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://drive.google.com/uc?export=download&id=1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4\" -O renderer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pfd53Hw2cfaY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-23 11:19:12--  https://drive.google.com/uc?export=download&id=1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR\n",
      "Resolving drive.google.com (drive.google.com)... 216.58.193.78, 2607:f8b0:4005:80b::200e\n",
      "Connecting to drive.google.com (drive.google.com)|216.58.193.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0c-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/28puvbbfp8mo5sfq1ot14qfikmfkggut/1563904800000/10102393604162075786/*/1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2019-07-23 11:19:15--  https://doc-0c-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/28puvbbfp8mo5sfq1ot14qfikmfkggut/1563904800000/10102393604162075786/*/1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR?e=download\n",
      "Resolving doc-0c-58-docs.googleusercontent.com (doc-0c-58-docs.googleusercontent.com)... 172.217.14.225, 2607:f8b0:400a:804::2001\n",
      "Connecting to doc-0c-58-docs.googleusercontent.com (doc-0c-58-docs.googleusercontent.com)|172.217.14.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘actor.pkl’\n",
      "\n",
      "actor.pkl               [  <=>               ]  42.82M   151MB/s    in 0.3s    \n",
      "\n",
      "2019-07-23 11:19:16 (151 MB/s) - ‘actor.pkl’ saved [44898539]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://drive.google.com/uc?export=download&id=1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR\" -O actor.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZpb3_3QiMZw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-23 11:19:22--  https://raw.githubusercontent.com/hzwer/LearningToPaint/master/image/Trump.png\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.52.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.52.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36916 (36K) [image/png]\n",
      "Saving to: ‘image/test.png’\n",
      "\n",
      "image/test.png      100%[===================>]  36.05K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2019-07-23 11:19:22 (4.38 MB/s) - ‘image/test.png’ saved [36916/36916]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -U NoSuchBrowser/1.0 -O image/test.png https://raw.githubusercontent.com/hzwer/LearningToPaint/master/image/Trump.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brX4ZlQoc9ss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canvas step 0, L2Loss = 0.02452566847205162\n",
      "canvas step 1, L2Loss = 0.01579287461936474\n",
      "canvas step 2, L2Loss = 0.011334840208292007\n",
      "canvas step 3, L2Loss = 0.00941722933202982\n",
      "canvas step 4, L2Loss = 0.00839623250067234\n",
      "canvas step 5, L2Loss = 0.007518631871789694\n",
      "canvas step 6, L2Loss = 0.007007237523794174\n",
      "canvas step 7, L2Loss = 0.00652341078966856\n",
      "canvas step 8, L2Loss = 0.0060240719467401505\n",
      "canvas step 9, L2Loss = 0.005599963944405317\n",
      "canvas step 10, L2Loss = 0.00539620965719223\n",
      "canvas step 11, L2Loss = 0.005166861694306135\n",
      "canvas step 12, L2Loss = 0.0050448025576770306\n",
      "canvas step 13, L2Loss = 0.004918115213513374\n",
      "canvas step 14, L2Loss = 0.004706248641014099\n",
      "canvas step 15, L2Loss = 0.004534490406513214\n",
      "canvas step 16, L2Loss = 0.0044345129281282425\n",
      "canvas step 17, L2Loss = 0.004319433588534594\n",
      "canvas step 18, L2Loss = 0.0042464639991521835\n",
      "canvas step 19, L2Loss = 0.004121042788028717\n",
      "canvas step 20, L2Loss = 0.004020751919597387\n",
      "canvas step 21, L2Loss = 0.003949125297367573\n",
      "canvas step 22, L2Loss = 0.003874519607052207\n",
      "canvas step 23, L2Loss = 0.0038239657878875732\n",
      "canvas step 24, L2Loss = 0.0037823119200766087\n",
      "canvas step 25, L2Loss = 0.003676449414342642\n",
      "canvas step 26, L2Loss = 0.003647626843303442\n",
      "canvas step 27, L2Loss = 0.003526765387505293\n",
      "canvas step 28, L2Loss = 0.003445766866207123\n",
      "canvas step 29, L2Loss = 0.0034033632837235928\n",
      "canvas step 30, L2Loss = 0.0033437234815210104\n",
      "canvas step 31, L2Loss = 0.003306069876998663\n",
      "canvas step 32, L2Loss = 0.0032422300428152084\n",
      "canvas step 33, L2Loss = 0.003213740885257721\n",
      "canvas step 34, L2Loss = 0.003176793921738863\n",
      "canvas step 35, L2Loss = 0.003142896806821227\n",
      "canvas step 36, L2Loss = 0.003081131260842085\n",
      "canvas step 37, L2Loss = 0.003042648546397686\n",
      "canvas step 38, L2Loss = 0.003008836880326271\n",
      "canvas step 39, L2Loss = 0.0030050077475607395\n",
      "divided canvas step 0, L2Loss = 0.0017135185189545155\n",
      "divided canvas step 1, L2Loss = 0.001328138168901205\n",
      "divided canvas step 2, L2Loss = 0.001089920406229794\n",
      "divided canvas step 3, L2Loss = 0.000939980149269104\n",
      "divided canvas step 4, L2Loss = 0.0008437768556177616\n",
      "divided canvas step 5, L2Loss = 0.0007716566324234009\n",
      "divided canvas step 6, L2Loss = 0.0007249336922541261\n",
      "divided canvas step 7, L2Loss = 0.0006803981377743185\n",
      "divided canvas step 8, L2Loss = 0.000644226442091167\n",
      "divided canvas step 9, L2Loss = 0.0006122770137153566\n",
      "divided canvas step 10, L2Loss = 0.0005828093853779137\n",
      "divided canvas step 11, L2Loss = 0.0005581735167652369\n",
      "divided canvas step 12, L2Loss = 0.0005326837999746203\n",
      "divided canvas step 13, L2Loss = 0.0005114878877066076\n",
      "divided canvas step 14, L2Loss = 0.0004914472228847444\n",
      "divided canvas step 15, L2Loss = 0.0004728994390461594\n",
      "divided canvas step 16, L2Loss = 0.0004575791535899043\n",
      "divided canvas step 17, L2Loss = 0.00044369196984916925\n",
      "divided canvas step 18, L2Loss = 0.0004339948354754597\n",
      "divided canvas step 19, L2Loss = 0.00042461976408958435\n",
      "divided canvas step 20, L2Loss = 0.00041578098898753524\n",
      "divided canvas step 21, L2Loss = 0.0004071547300554812\n",
      "divided canvas step 22, L2Loss = 0.00039858321542851627\n",
      "divided canvas step 23, L2Loss = 0.0003920065064448863\n",
      "divided canvas step 24, L2Loss = 0.0003875289694406092\n",
      "divided canvas step 25, L2Loss = 0.0003825024759862572\n",
      "divided canvas step 26, L2Loss = 0.00037796288961544633\n",
      "divided canvas step 27, L2Loss = 0.0003735522914212197\n",
      "divided canvas step 28, L2Loss = 0.0003685865376610309\n",
      "divided canvas step 29, L2Loss = 0.00036427925806492567\n",
      "divided canvas step 30, L2Loss = 0.00035950742312707007\n",
      "divided canvas step 31, L2Loss = 0.00035495334304869175\n",
      "divided canvas step 32, L2Loss = 0.0003508605877868831\n",
      "divided canvas step 33, L2Loss = 0.0003468223148956895\n",
      "divided canvas step 34, L2Loss = 0.0003417088300921023\n",
      "divided canvas step 35, L2Loss = 0.000337369303451851\n",
      "divided canvas step 36, L2Loss = 0.0003332709602545947\n",
      "divided canvas step 37, L2Loss = 0.00032794702565297484\n",
      "divided canvas step 38, L2Loss = 0.00032343529164791107\n",
      "divided canvas step 39, L2Loss = 0.0003193923330400139\n"
     ]
    }
   ],
   "source": [
    "!python3 baseline/test.py --max_step=80 --actor=actor.pkl --renderer=renderer.pkl --img=image/test.png --divide=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLM4U6F0_yjV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ffmpeg: not found\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -r 30 -f image2 -i output/generated%d.png -s 512x512 -c:v libx264 -pix_fmt yuv420p video.mp4 -q:v 0 -q:a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekY7HcBeh8zl"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import moviepy.editor as mpy\n",
    "display(mpy.ipython_display('video.mp4', height=256, max_duration=100.))\n",
    "display(Image('output/generated399.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-p0NhqyTqO_"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXAV9RwkTwKh"
   },
   "outputs": [],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzZUVjdrET2G"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgguAW3eETVd"
   },
   "outputs": [],
   "source": [
    "!unzip img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBH--DY-sK8V"
   },
   "outputs": [],
   "source": [
    "!rm img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6mVpjvBvzrb"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PYJVt8pc6BP"
   },
   "outputs": [],
   "source": [
    "!python3 baseline/train_renderer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZWjNmD23gKm"
   },
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehnzhWn9GG4I"
   },
   "outputs": [],
   "source": [
    "%%writefile baseline/env.py\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from DRL.ddpg import decode\n",
    "from utils.util import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aug = transforms.Compose(\n",
    "            [transforms.ToPILImage(),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             ])\n",
    "\n",
    "width = 128\n",
    "convas_area = width * width\n",
    "\n",
    "img_train = []\n",
    "img_test = []\n",
    "train_num = 0\n",
    "test_num = 0\n",
    "\n",
    "class Paint:\n",
    "    def __init__(self, batch_size, max_step):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_step = max_step\n",
    "        self.action_space = (13)\n",
    "        self.observation_space = (self.batch_size, width, width, 7)\n",
    "        self.test = False\n",
    "        \n",
    "    def load_data(self):\n",
    "        # CelebA\n",
    "        global train_num, test_num\n",
    "        for i in range(200000):\n",
    "            img_id = '%06d' % (i + 1)\n",
    "            try:\n",
    "                img = cv2.imread('./data/img_align_celeba/' + img_id + '.jpg', cv2.IMREAD_UNCHANGED)\n",
    "                img = cv2.resize(img, (width, width))\n",
    "                if i > 2000:                \n",
    "                    train_num += 1\n",
    "                    img_train.append(img)\n",
    "                else:\n",
    "                    test_num += 1\n",
    "                    img_test.append(img)\n",
    "            finally:\n",
    "                if (i + 1) % 10000 == 0:                    \n",
    "                    print('loaded {} images'.format(i + 1))\n",
    "        print('finish loading data, {} training images, {} testing images'.format(str(train_num), str(test_num)))\n",
    "        \n",
    "    def pre_data(self, id, test):\n",
    "        if test:\n",
    "            img = img_test[id]\n",
    "        else:\n",
    "            img = img_train[id]\n",
    "        if not test:\n",
    "            img = aug(img)\n",
    "        img = np.asarray(img)\n",
    "        return np.transpose(img, (2, 0, 1))\n",
    "    \n",
    "    def reset(self, test=False, begin_num=False):\n",
    "        self.test = test\n",
    "        self.imgid = [0] * self.batch_size\n",
    "        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
    "        for i in range(self.batch_size):\n",
    "            if test:\n",
    "                id = (i + begin_num)  % test_num\n",
    "            else:\n",
    "                id = np.random.randint(train_num)\n",
    "            self.imgid[i] = id\n",
    "            self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
    "        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n",
    "        self.stepnum = 0\n",
    "        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
    "        self.lastdis = self.ini_dis = self.cal_dis()\n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        # canvas B * 3 * width * width\n",
    "        # gt B * 3 * width * width\n",
    "        # T B * 1 * width * width\n",
    "        ob = []\n",
    "        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n",
    "        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n",
    "\n",
    "    def cal_trans(self, s, t):\n",
    "        return (s.transpose(0, 3) * t).transpose(0, 3)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte()\n",
    "        self.stepnum += 1\n",
    "        ob = self.observation()\n",
    "        done = (self.stepnum == self.max_step)\n",
    "        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n",
    "        return ob.detach(), reward, np.array([done] * self.batch_size), None\n",
    "\n",
    "    def cal_dis(self):\n",
    "        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n",
    "    \n",
    "    def cal_reward(self):\n",
    "        dis = self.cal_dis()\n",
    "        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n",
    "        self.lastdis = dis\n",
    "        return to_numpy(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kwVmo6yv1w3"
   },
   "outputs": [],
   "source": [
    "!python3 baseline/train.py --max_step=200 --debug --batch_size=96"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
